#imports
import streamlit as st
import re
import time
from bs4 import BeautifulSoup
from selenium import webdriver
import re, time, os
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline
import os
from dotenv import load_dotenv
from groq import Groq

#progress bar:
def progress_bar(progress):

    progress_bar_text = progress_text
    my_bar=st.progress(0,text=progress_bar)
    success_bar_text = success_text

    for percent_complete in range(100):
        time.sleep(0.01)
        my_bar.progress(percent_complete+1, text=progress_bar_text)
    time.sleep(1)
    print(success_bar_text)


#SCRAPER FUNCTIONS/IMPORTS/COMPONENTS------------------------------------------------------------------------------

#define driver
driver = webdriver.Firefox()

#get soup for page
def soupify_url(url, driver=driver):
    driver.get(url)
    return BeautifulSoup(driver.page_source, 'html.parser')

#scraper
def scraper(link, driver=driver):
    print(f"Scraping {link}")

    driver.get(link)
    time.sleep(2)

    html = driver.page_source
    raw_soup = BeautifulSoup(html, features="html.parser")
    
    paragraphs = raw_soup.find_all('p')

    return " ".join([p.get_text(" ", strip=True) for p in paragraphs])

#make file name from url
def file_name_from_url(url):
    file_name = url.split("/")[2].replace(".", "").replace('www', '')

    return f"{file_name}_soup.txt"

#list for error urls
errored_urls = []
scrape_list = []
#-----------------------------------------------------------------------------------------------------------------
#SUMMARIZER FUNCTIONS/COMPONENTS----------------------------------------------------------------------------------
def summarize(text):
    model_name = "allenai/led-large-16384-arxiv"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

    pipe = pipeline("text2text-generation", model=model, tokenizer=tokenizer, device=-1)

    result = pipe(
        text,
        truncation=True, 
        max_length=750, 
        no_repeat_ngram_size=5, 
        num_beams=3, 
        early_stopping=True
        )
    
    summary = result[0]['generated_text']
    return summary

#STREAMLIT--------------------------------------------------------------------------------------------------------
st.set_page_config(layout="wide")
st.title("Determine a company's NAICS code",)
col1, col2 = st.columns(2)

with st.sidebar:
    st.markdown('''# North American Insurance Classification System (NAICS)''')
    st.markdown('''information about naics codes, what they are, what they do, etc''')

urls = []

with col1:
    st.header("Enter Company Information", divider="red")
    company_url = st.text_input("Enter link(s) with company information here:")
    urls.append(company_url)

    # Validate the URL
    if company_url:
        if company_url.startswith("http://") or company_url.startswith("https://"):
            st.success(f"Valid URL: {company_url}")

            for url in urls:
                try:
                    with st.spinner("Scraping Page(s)"):
                        processed_soup = scraper(url)

                    #add scraped content to list
                    scrape_list.append(processed_soup)

                except Exception as e: 
                    errored_urls.append(url)
                    print("\n\nError: ", url, "could not be scraped because:")
                    print(e, "\n\n")
                    continue
                #show all error urls
                print("Errored urls:")
                for url in errored_urls:
                    print(url)
            driver.close()

            with st.spinner("Summarizing Information"):
                summarized = summarize(text=scrape_list)
                
            # Display a loading message
            with st.spinner("NAICS code loading..."):
                load_dotenv()
                api_key = os.getenv("APIkey")
                client = Groq(api_key=api_key)

                # Prompt preparation
                website = f"{url}"
                user_prompt = f"""Consider the following examples: 
                    According to the company’s website, https://ascofwi.com/,  Advanced Spine Center of Wisconsin, LLC is an outpatient surgery center which specializes in spinal surgeries. The business’ NAICS code is 621498 - All Other Outpatient Care Centers. 
                    According to the company’s website, https://www.goldkeypropertiesal.com/, GOLD KEY PROPERTIES LLC is a real estate company specializing in helping customers buy or sell Single Family homes, Condominiums, Townhouses, Land, and Commercial real estate purchases. The business’ NAICS code is 531210 - Offices of Real Estate Agents and Brokers. 
                    According to the company’s website, https://www.fundapps.co/, FUNDAPPS LLC makes regulatory software for cloud-based compliance monitoring and reporting. The business’ NAICS code is 541512 - Computer Systems Design Services. 
                    According to the company’s website, https://shop.lamy.com/en, Lamy Inc manufactures and sells high end writing instruments and accessories.  Their products include a variety of pens, painting and drawing supplies, and ink. The business’ NAICS code is 339940 - Office Supplies (except Paper) Manufacturing. 
                    According to the company’s website, https://wtgrantfoundation.org/, the WILLIAM T. GRANT FOUNDATION, INC. is a non-profit organization which invests in high-quality research focused on reducing inequality in youth outcomes and improving the use of research evidence in decisions that affect young people in the United States. The business’ NAICS code is 813211 - Grantmaking Foundations. 

                    Given the data that was scraped from {website} and these examples, identify the most probable NAICS code and NAICS title. ONLY PROVIDE THE NAICS CODE, NO OTHER TEXT. 
                """

                completion = client.chat.completions.create(
                    model="llama3-8b-8192",
                    messages=[
                        {"role": "user", "content": summarized},
                        {"role": "user", "content": user_prompt}
                        ],
                    temperature=1,
                    max_tokens=1024,
                    top_p=1,
                    stream=True,
                    stop=None
                )    

                naics_code = ""

                for chunk in completion:
                    naics_code += chunk.choices[0].delta.content or ""
                
                # Display results
                st.success(f"NAICS code determined: {naics_code.strip()}")
            
            # st.success("NAICS code determined!")

        else:
            st.error("Please enter a valid URL starting with http:// or https://")

    #SCRAPING------------------------------------------------------------------------------------------------------


with col2:
    st.header("Instructions", divider="red")
    st.markdown('''
                ***Please do not close the Firefox window that opens with this streamlit app until NAICS code is returned***''')
    st.markdown('''### Enter link(s) to website for company you want to classify''')
    st.markdown('''Enter at least one url that links to page(s) with the most information about the company you with to classify.
                Company information is commonly found on "About", "Services", or "Home" pages.
                Sometimes you may need to include more than one url to link to a company's offerings. 
                If including more than one url, separate urls with a comma (example: https://www.naics.com/, https://www.naics.com/search/ ''')
    st.markdown('''### Click the 'Enter' key and wait for a NAICS code to be returned''')
    st.markdown('''This process can take a few minutes. Please be patient and let the app run.''')
    st.markdown('''### NAICS Code is returned!''')
    st.markdown('''You can now close out of any additional pages that opened while the app was running.''')